{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-30T03:59:49.682244Z","iopub.execute_input":"2024-04-30T03:59:49.682693Z","iopub.status.idle":"2024-04-30T03:59:49.693133Z","shell.execute_reply.started":"2024-04-30T03:59:49.682662Z","shell.execute_reply":"2024-04-30T03:59:49.691731Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"import other libraries","metadata":{}},{"cell_type":"code","source":"!pip install mord","metadata":{"execution":{"iopub.status.busy":"2024-04-30T03:59:49.695345Z","iopub.execute_input":"2024-04-30T03:59:49.695728Z","iopub.status.idle":"2024-04-30T04:00:32.537913Z","shell.execute_reply.started":"2024-04-30T03:59:49.695699Z","shell.execute_reply":"2024-04-30T04:00:32.536708Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79458a758130>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/mord/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79458a7582e0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/mord/\u001b[0m\u001b[33m\n\u001b[0m^C\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import cohen_kappa_score, make_scorer, classification_report, accuracy_score, confusion_matrix\nimport re\nfrom sklearn.pipeline import Pipeline\n# from sklearn.pipeline import FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer\n\nfrom gensim.models import Word2Vec\nfrom mord import OrdinalRidge\nimport seaborn as sns\n# import statsmodels.api as sm\n# from statsmodels.miscmodels.ordinal_model import OrderedModel","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.539539Z","iopub.execute_input":"2024-04-30T04:00:32.539863Z","iopub.status.idle":"2024-04-30T04:00:32.594611Z","shell.execute_reply.started":"2024-04-30T04:00:32.539833Z","shell.execute_reply":"2024-04-30T04:00:32.589494Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, FunctionTransformer\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmord\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrdinalRidge\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# import statsmodels.api as sm\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# from statsmodels.miscmodels.ordinal_model import OrderedModel\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mord'"],"ename":"ModuleNotFoundError","evalue":"No module named 'mord'","output_type":"error"}]},{"cell_type":"markdown","source":"Read in the dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ndf_test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')\ndf_sub = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.595820Z","iopub.status.idle":"2024-04-30T04:00:32.596238Z","shell.execute_reply.started":"2024-04-30T04:00:32.596043Z","shell.execute_reply":"2024-04-30T04:00:32.596060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data cleaning","metadata":{}},{"cell_type":"code","source":"def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\n\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    phrase = re.sub(r\"\\xa0\",\" \",phrase)\n    return phrase.strip()\n\ndef clean_text(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return decontracted(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.597521Z","iopub.status.idle":"2024-04-30T04:00:32.597915Z","shell.execute_reply.started":"2024-04-30T04:00:32.597729Z","shell.execute_reply":"2024-04-30T04:00:32.597744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['full_text'] = df_train['full_text'].apply(clean_text)\ndf_test['full_text'] = df_test['full_text'].apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.600009Z","iopub.status.idle":"2024-04-30T04:00:32.600417Z","shell.execute_reply.started":"2024-04-30T04:00:32.600203Z","shell.execute_reply":"2024-04-30T04:00:32.600218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['full_text'][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.601422Z","iopub.status.idle":"2024-04-30T04:00:32.601818Z","shell.execute_reply.started":"2024-04-30T04:00:32.601637Z","shell.execute_reply":"2024-04-30T04:00:32.601653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"feature extraction - maybe add in more features like bag of words/ keywords?","metadata":{}},{"cell_type":"markdown","source":"create a word_count and text length column","metadata":{}},{"cell_type":"code","source":"df_train['word_count'] = df_train[\"full_text\"].str.split().str.len()\ndf_test['word_count'] = df_test[\"full_text\"].str.split().str.len()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.602801Z","iopub.status.idle":"2024-04-30T04:00:32.603148Z","shell.execute_reply.started":"2024-04-30T04:00:32.602980Z","shell.execute_reply":"2024-04-30T04:00:32.602994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['length'] = df_train[\"full_text\"].str.len()\ndf_test['length'] = df_test[\"full_text\"].str.len()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.604561Z","iopub.status.idle":"2024-04-30T04:00:32.604938Z","shell.execute_reply.started":"2024-04-30T04:00:32.604756Z","shell.execute_reply":"2024-04-30T04:00:32.604770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.606448Z","iopub.status.idle":"2024-04-30T04:00:32.606808Z","shell.execute_reply.started":"2024-04-30T04:00:32.606639Z","shell.execute_reply":"2024-04-30T04:00:32.606653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"attempt at creating vector embeddings:","metadata":{}},{"cell_type":"code","source":"word2vec_model = Word2Vec(df_train['full_text'], \n                          vector_size=100,\n                          min_count=1,\n                          window=5, \n                          )","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.607736Z","iopub.status.idle":"2024-04-30T04:00:32.608106Z","shell.execute_reply.started":"2024-04-30T04:00:32.607912Z","shell.execute_reply":"2024-04-30T04:00:32.607925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vectorize_text(text, word2vec_model):\n    text_vector = np.zeros(100)  # Initialize a vector of zeros (100-dimensional)\n    for word in text.split():  # Split text into words\n        if word in word2vec_model.wv:  # Check if word is in the vocabulary\n            text_vector += word2vec_model.wv[word]  # Add word vector to the text vector\n    return text_vector","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.610205Z","iopub.status.idle":"2024-04-30T04:00:32.610602Z","shell.execute_reply.started":"2024-04-30T04:00:32.610422Z","shell.execute_reply":"2024-04-30T04:00:32.610438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the vectorize_text function to each text entry in train_df['full_text']\ndf_train['text_vector'] = df_train['full_text'].apply(lambda x: vectorize_text(x, word2vec_model))\ndf_test['text_vector'] = df_test['full_text'].apply(lambda x: vectorize_text(x, word2vec_model))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.611753Z","iopub.status.idle":"2024-04-30T04:00:32.612145Z","shell.execute_reply.started":"2024-04-30T04:00:32.611941Z","shell.execute_reply":"2024-04-30T04:00:32.611956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.613700Z","iopub.status.idle":"2024-04-30T04:00:32.614091Z","shell.execute_reply.started":"2024-04-30T04:00:32.613904Z","shell.execute_reply":"2024-04-30T04:00:32.613919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = df_train['full_text']\n# y_train = df_train['score']\n# X_test = df_test['full_text']\n# y_test = df_sub['score']","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.615632Z","iopub.status.idle":"2024-04-30T04:00:32.616020Z","shell.execute_reply.started":"2024-04-30T04:00:32.615837Z","shell.execute_reply":"2024-04-30T04:00:32.615852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"this method trains and evaluates each pipeline \nreturns the y_pred and quadratic weighted kappa score of the model","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate_pipeline(pipeline, X_train, y_train, X_test, y_test):\n    pipeline.fit(X_train, y_train)\n    y_pred = pipeline.predict(X_test)\n    \n    kappa = cohen_kappa_score(y_test, y_pred, weights='quadratic')\n    \n    print()\n    print('Classifier used: ', pipeline.named_steps['classifier'])\n    print('y_test: ', y_test.tolist()[0:10])\n    print('y_pred: ', y_pred.tolist()[0:10])\n    print('quadratic weighted kappa score: ', kappa)\n    \n    return pipeline, y_pred","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.617728Z","iopub.status.idle":"2024-04-30T04:00:32.618134Z","shell.execute_reply.started":"2024-04-30T04:00:32.617944Z","shell.execute_reply":"2024-04-30T04:00:32.617959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"method for performing cross_validation of pipelines and showing their average performances","metadata":{}},{"cell_type":"code","source":"#define quadratic weighted kappa as a custom scorer\nqwk_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n\ndef pipeline_cross_validation(pipeline, X_train, y_train, qwk_scorer=qwk_scorer):\n    # Define cross-validation strategy and perform cross-validation\n    scoring = {'accuracy': 'accuracy', 'f1_weighted': 'f1_weighted', 'qwk': qwk_scorer}\n    cv_results = cross_validate(pipeline, X_train, y_train, cv=5, scoring=scoring)\n\n    # Print cross-validation results\n    print(\"Mean Accuracy:\", np.mean(cv_results['test_accuracy']))\n    print(\"Mean Weighted F1-score:\", np.mean(cv_results['test_f1_weighted']))\n    print(\"Mean Quadratic Weighted Kappa Score:\", np.mean(cv_results['test_qwk']))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.620546Z","iopub.status.idle":"2024-04-30T04:00:32.621243Z","shell.execute_reply.started":"2024-04-30T04:00:32.620927Z","shell.execute_reply":"2024-04-30T04:00:32.620954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create the tfidf","metadata":{}},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(stop_words='english', min_df=0.05, max_df=0.95,)\n# tfidf = tfidf_vectorizer.fit_transform(X_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.622933Z","iopub.status.idle":"2024-04-30T04:00:32.623565Z","shell.execute_reply.started":"2024-04-30T04:00:32.623236Z","shell.execute_reply":"2024-04-30T04:00:32.623259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create the multinomial logistic regression classifier","metadata":{}},{"cell_type":"code","source":"logreg_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.625193Z","iopub.status.idle":"2024-04-30T04:00:32.625780Z","shell.execute_reply.started":"2024-04-30T04:00:32.625503Z","shell.execute_reply":"2024-04-30T04:00:32.625527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create a pipeline for logistic regression classifier","metadata":{}},{"cell_type":"code","source":"# Define a transformer to extract 'text_vector' from DataFrame\ndef get_text_vector(df):\n    return np.vstack(df['text_vector'])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.627115Z","iopub.status.idle":"2024-04-30T04:00:32.627670Z","shell.execute_reply.started":"2024-04-30T04:00:32.627404Z","shell.execute_reply":"2024-04-30T04:00:32.627426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_preprocessor = ColumnTransformer(\n    transformers=[\n        ('text', tfidf_vectorizer, 'full_text'),\n        ('word_count', StandardScaler(), ['word_count']),\n        ('length', StandardScaler(), ['length'])\n    ],\n    remainder='passthrough'\n)\n\nw2v_preprocessor = ColumnTransformer(\n    transformers=[\n#         ('text', tfidf_vectorizer, 'full_text'),\n        ('text_vector', FunctionTransformer(get_text_vector, validate=False), ['text_vector']),\n        ('word_count', StandardScaler(), ['word_count']),\n        ('length', StandardScaler(), ['length'])\n    ],\n    remainder='passthrough'\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.629513Z","iopub.status.idle":"2024-04-30T04:00:32.630079Z","shell.execute_reply.started":"2024-04-30T04:00:32.629787Z","shell.execute_reply":"2024-04-30T04:00:32.629809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg_pipeline = Pipeline(steps=[\n#     ('tfidf', tfidf_vectorizer),\n    ('preprocessor', tfidf_preprocessor),\n    ('classifier', logreg_clf)\n])\n\nw2v_logreg_pipeline = Pipeline(steps=[\n    ('preprocessor', w2v_preprocessor),\n    ('classifier', logreg_clf)\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.631619Z","iopub.status.idle":"2024-04-30T04:00:32.632153Z","shell.execute_reply.started":"2024-04-30T04:00:32.631895Z","shell.execute_reply":"2024-04-30T04:00:32.631916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"fit and make a prediction","metadata":{}},{"cell_type":"code","source":"# df_sub['essay_id'].tolist()\n# df_train.loc[(df_train['essay_id'] == '000d118') | (df_train['essay_id'] =='000fe60') | (df_train['essay_id'] =='001ab80')]\n# sub_df_data = df_train.loc[(df_train['essay_id'] == '000d118') | (df_train['essay_id'] =='000fe60') | (df_train['essay_id'] =='001ab80')]\n# X_test3 = tfidf_vectorizer.transform(df_test['full_text'])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.634093Z","iopub.status.idle":"2024-04-30T04:00:32.634642Z","shell.execute_reply.started":"2024-04-30T04:00:32.634381Z","shell.execute_reply":"2024-04-30T04:00:32.634403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train[['full_text', 'word_count', 'length']]\n# X = df_train['full_text']\ny = df_train['score']\nsub_X = df_test[['full_text', 'word_count', 'length']]\nsub_y = df_sub['score']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)\n\nX2 = df_train[['word_count', 'length', 'text_vector']]\nsub_X2 = df_test[['word_count', 'length', 'text_vector']]\n\n# X2 = np.array(df_train['text_vector'].tolist())\n# sub_X2 = np.array(df_test['text_vector'].tolist())\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y, train_size = 0.8)\n\n\n# trained_logreg_pipeline, logreg_y_pred = train_and_evaluate_pipeline(logreg_pipeline, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.635653Z","iopub.status.idle":"2024-04-30T04:00:32.636006Z","shell.execute_reply.started":"2024-04-30T04:00:32.635844Z","shell.execute_reply":"2024-04-30T04:00:32.635858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_logreg_pipeline, logreg_y_pred = train_and_evaluate_pipeline(logreg_pipeline, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.637088Z","iopub.status.idle":"2024-04-30T04:00:32.637503Z","shell.execute_reply.started":"2024-04-30T04:00:32.637298Z","shell.execute_reply":"2024-04-30T04:00:32.637312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"commented off just to make the notebook save and rerun properly, need to use a different clf if plan to keep","metadata":{}},{"cell_type":"code","source":"# trained_logreg_pipeline2, logreg_y_pred2 = train_and_evaluate_pipeline(w2v_logreg_pipeline, X_train2, y_train2, X_test2, y_test2)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.638983Z","iopub.status.idle":"2024-04-30T04:00:32.639366Z","shell.execute_reply.started":"2024-04-30T04:00:32.639169Z","shell.execute_reply":"2024-04-30T04:00:32.639183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_cross_validation(logreg_pipeline, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.640758Z","iopub.status.idle":"2024-04-30T04:00:32.641112Z","shell.execute_reply.started":"2024-04-30T04:00:32.640945Z","shell.execute_reply":"2024-04-30T04:00:32.640960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, logreg_y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.642237Z","iopub.status.idle":"2024-04-30T04:00:32.642627Z","shell.execute_reply.started":"2024-04-30T04:00:32.642451Z","shell.execute_reply":"2024-04-30T04:00:32.642466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model prediction on submission essays: \", trained_logreg_pipeline.predict(sub_X).tolist())\nprint('Submission essays actual classes: ', sub_y.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.643636Z","iopub.status.idle":"2024-04-30T04:00:32.644001Z","shell.execute_reply.started":"2024-04-30T04:00:32.643817Z","shell.execute_reply":"2024-04-30T04:00:32.643838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# logregcv_clf = LogisticRegressionCV(multi_class='multinomial', cv=5, solver='lbfgs', max_iter=1000, refit=True, scoring=qwk_scorer)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.645479Z","iopub.status.idle":"2024-04-30T04:00:32.645843Z","shell.execute_reply.started":"2024-04-30T04:00:32.645674Z","shell.execute_reply":"2024-04-30T04:00:32.645689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create a lightgbm model pipeline\n\nlgbm over xgboost for performance and scalability? maybe elaborate more","metadata":{}},{"cell_type":"code","source":"lgbm_clf = LGBMClassifier(objective='multiclass', num_class=6, metric='multi_logloss', num_leaves=31, learning_rate=0.1, feature_fraction=0.6)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.647668Z","iopub.status.idle":"2024-04-30T04:00:32.648083Z","shell.execute_reply.started":"2024-04-30T04:00:32.647884Z","shell.execute_reply":"2024-04-30T04:00:32.647901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_pipeline = Pipeline(steps=[\n#     ('tfidf', tfidf_vectorizer),   # TF-IDF Vectorizer\n    ('preprocessor', tfidf_preprocessor),\n    ('classifier', lgbm_clf) # LightGBM Classifier\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.649546Z","iopub.status.idle":"2024-04-30T04:00:32.649926Z","shell.execute_reply.started":"2024-04-30T04:00:32.649743Z","shell.execute_reply":"2024-04-30T04:00:32.649759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"use some GridSearchCV to find the best parameters","metadata":{}},{"cell_type":"code","source":"# parameter grid used for the grid search:\nparam_grid = {\n    'num_leaves': [31, 50, 100],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'feature_fraction': [0.6, 0.8, 0.9]\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.651408Z","iopub.status.idle":"2024-04-30T04:00:32.651829Z","shell.execute_reply.started":"2024-04-30T04:00:32.651633Z","shell.execute_reply":"2024-04-30T04:00:32.651650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # create and fit the gridsearch\n# grid_search = GridSearchCV(estimator=lgbm_clf, param_grid=param_grid, cv=3, scoring=qwk_scorer)\n# grid_search.fit(tfidf_vectorizer.fit_transform(X_train), y_train)\n\n# # Print the best parameters and best score\n# print(\"Best Parameters: \", grid_search.best_params_)\n# print(\"Best Score (quadratic weighted kappa score): \", grid_search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.652898Z","iopub.status.idle":"2024-04-30T04:00:32.653283Z","shell.execute_reply.started":"2024-04-30T04:00:32.653104Z","shell.execute_reply":"2024-04-30T04:00:32.653121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_lgbm_pipeline, lgbm_y_pred = train_and_evaluate_pipeline(lgbm_pipeline, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.655691Z","iopub.status.idle":"2024-04-30T04:00:32.656064Z","shell.execute_reply.started":"2024-04-30T04:00:32.655897Z","shell.execute_reply":"2024-04-30T04:00:32.655912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"commented off just to make the notebook run faster for now","metadata":{}},{"cell_type":"code","source":"# pipeline_cross_validation(lgbm_pipeline, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.656783Z","iopub.status.idle":"2024-04-30T04:00:32.657161Z","shell.execute_reply.started":"2024-04-30T04:00:32.656985Z","shell.execute_reply":"2024-04-30T04:00:32.657001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, lgbm_y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.658119Z","iopub.status.idle":"2024-04-30T04:00:32.658504Z","shell.execute_reply.started":"2024-04-30T04:00:32.658300Z","shell.execute_reply":"2024-04-30T04:00:32.658314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trained_lgbm_pipeline.predict(df_test[['full_text', 'word_count', 'length']]).tolist()\nprint(\"Model prediction on submission essays: \", trained_lgbm_pipeline.predict(sub_X).tolist())\nprint('Submission essays actual classes: ', sub_y.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.660717Z","iopub.status.idle":"2024-04-30T04:00:32.661408Z","shell.execute_reply.started":"2024-04-30T04:00:32.661075Z","shell.execute_reply":"2024-04-30T04:00:32.661100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LogisticRegressionCV classifier model and pipeline","metadata":{}},{"cell_type":"code","source":"# logregcv_clf = LogisticRegressionCV(multi_class='multinomial', cv=3, solver='lbfgs', max_iter=1000, refit=True, scoring=qwk_scorer)\n\n# logregcv_pipeline = Pipeline(steps=[\n# #     ('tfidf', tfidf_vectorizer),\n#     ('preprocessor', preprocessor),\n#     ('classifier', logregcv_clf)\n# ])\n\n# logregcv_y_pred = train_and_evaluate_pipeline(logregcv_pipeline, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.663303Z","iopub.status.idle":"2024-04-30T04:00:32.663880Z","shell.execute_reply.started":"2024-04-30T04:00:32.663606Z","shell.execute_reply":"2024-04-30T04:00:32.663628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ordinal logistic regression classsifier","metadata":{}},{"cell_type":"code","source":"# train_input = df_train[['word_count', 'length', 'text_vector']]\n# np.asarray(train_input['text_vector'])\n# train_input['text_vector'] = np.asarray(train_input['text_vector'])\n# train_input","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.665304Z","iopub.status.idle":"2024-04-30T04:00:32.665869Z","shell.execute_reply.started":"2024-04-30T04:00:32.665595Z","shell.execute_reply":"2024-04-30T04:00:32.665616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df_train['text_vector'])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.667815Z","iopub.status.idle":"2024-04-30T04:00:32.668390Z","shell.execute_reply.started":"2024-04-30T04:00:32.668113Z","shell.execute_reply":"2024-04-30T04:00:32.668134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ordreg_clf = OrdinalRidge()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.669987Z","iopub.status.idle":"2024-04-30T04:00:32.670525Z","shell.execute_reply.started":"2024-04-30T04:00:32.670243Z","shell.execute_reply":"2024-04-30T04:00:32.670263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ordreg_pipeline = Pipeline(steps=[\n    ('preprocessor', tfidf_preprocessor),\n    ('classifier', ordreg_clf) # ordinal regression Classifier\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.672612Z","iopub.status.idle":"2024-04-30T04:00:32.673163Z","shell.execute_reply.started":"2024-04-30T04:00:32.672875Z","shell.execute_reply":"2024-04-30T04:00:32.672897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_ordreg_pipeline, ordreg_y_pred = train_and_evaluate_pipeline(ordreg_pipeline, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.674834Z","iopub.status.idle":"2024-04-30T04:00:32.675395Z","shell.execute_reply.started":"2024-04-30T04:00:32.675108Z","shell.execute_reply":"2024-04-30T04:00:32.675129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, ordreg_y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.676537Z","iopub.status.idle":"2024-04-30T04:00:32.676886Z","shell.execute_reply.started":"2024-04-30T04:00:32.676721Z","shell.execute_reply":"2024-04-30T04:00:32.676735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model prediction on submission essays: \", trained_ordreg_pipeline.predict(sub_X).tolist())\nprint('Submission essays actual classes: ', sub_y.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.678168Z","iopub.status.idle":"2024-04-30T04:00:32.678537Z","shell.execute_reply.started":"2024-04-30T04:00:32.678371Z","shell.execute_reply":"2024-04-30T04:00:32.678385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_cross_validation(ordreg_pipeline, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.679685Z","iopub.status.idle":"2024-04-30T04:00:32.680035Z","shell.execute_reply.started":"2024-04-30T04:00:32.679857Z","shell.execute_reply":"2024-04-30T04:00:32.679870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest Classifier ","metadata":{}},{"cell_type":"code","source":"rf_clf = RandomForestClassifier()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.691662Z","iopub.status.idle":"2024-04-30T04:00:32.692081Z","shell.execute_reply.started":"2024-04-30T04:00:32.691903Z","shell.execute_reply":"2024-04-30T04:00:32.691919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_pipeline = Pipeline(steps=[\n    ('preprocessor', tfidf_preprocessor),\n    ('classifier', rf_clf) # randomforest Classifier\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.693920Z","iopub.status.idle":"2024-04-30T04:00:32.694460Z","shell.execute_reply.started":"2024-04-30T04:00:32.694201Z","shell.execute_reply":"2024-04-30T04:00:32.694222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_rf_pipeline, rf_y_pred = train_and_evaluate_pipeline(rf_pipeline, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.695950Z","iopub.status.idle":"2024-04-30T04:00:32.696382Z","shell.execute_reply.started":"2024-04-30T04:00:32.696182Z","shell.execute_reply":"2024-04-30T04:00:32.696199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_cross_validation(rf_pipeline, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.697523Z","iopub.status.idle":"2024-04-30T04:00:32.697871Z","shell.execute_reply.started":"2024-04-30T04:00:32.697706Z","shell.execute_reply":"2024-04-30T04:00:32.697721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, rf_y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.699631Z","iopub.status.idle":"2024-04-30T04:00:32.700001Z","shell.execute_reply.started":"2024-04-30T04:00:32.699827Z","shell.execute_reply":"2024-04-30T04:00:32.699841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model prediction on submission essays: \", trained_rf_pipeline.predict(sub_X).tolist())\nprint('Submission essays actual classes: ', sub_y.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.701117Z","iopub.status.idle":"2024-04-30T04:00:32.701824Z","shell.execute_reply.started":"2024-04-30T04:00:32.701631Z","shell.execute_reply":"2024-04-30T04:00:32.701649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ordinal_clf = sm.OrdinalModel(y_train, tfidf_vectorizer.transform(X_train['full_text']))\n\n# ordered_model = OrderedModel(y_train,\n#                        tfidf_vectorizer.fit_transform(X_train['full_text']).toarray(),\n#                         distr='probit')\n\n# ordered_res = ordered_model.fit()\n# ordered_res.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.702837Z","iopub.status.idle":"2024-04-30T04:00:32.703203Z","shell.execute_reply.started":"2024-04-30T04:00:32.703024Z","shell.execute_reply":"2024-04-30T04:00:32.703038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicted_probs = ordered_results.predict(tfidf_vectorizer.fit_transform(X_test['full_text']).toarray())\n# predicted_probs","metadata":{"execution":{"iopub.status.busy":"2024-04-30T04:00:32.704271Z","iopub.status.idle":"2024-04-30T04:00:32.705248Z","shell.execute_reply.started":"2024-04-30T04:00:32.705049Z","shell.execute_reply":"2024-04-30T04:00:32.705067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Things to do:***\n\n- put explanations and more markup in notebook\n\n- more EDA, some diagrams and graphs on the dataset \n\n    ideas: - compare the cross validation qwk scores, group by scores and show word lengths etc\n\n- try word2vec for vector embeddings and compare with tfidf - make w2v more accurate somehow\n\n- find more models - potential: xgboostclassifier, ordinal logistic regression (sm), SGDClassifier? ,\n\n- overall increase the performance of the models they arent predicting the test dataset 100% correctly\n\n","metadata":{}},{"cell_type":"raw","source":"","metadata":{}}]}